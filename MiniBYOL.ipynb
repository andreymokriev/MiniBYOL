{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Версии библиотек\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Matplotlib: {plt.matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аугментация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTransform:\n",
    "    # Возвращает две разные версии одного изображеня\n",
    "    def __init__(self, base_transform):\n",
    "        self.base = base_transform\n",
    "    def __call__(self, x):\n",
    "        return self.base(x), self.base(x)\n",
    "\n",
    "# Сдвиг, кадрирование, поворот и нормализация\n",
    "\n",
    "# Для обучения BYOL\n",
    "mnist_aug = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomAffine(0, translate=(0.1,0.1), scale=(0.9,1.1), shear=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # mean и std пикселей на MNIST\n",
    "])\n",
    "\n",
    "# Для проверки линейной головы\n",
    "linear_aug = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример исходного и аугментированных изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_ds = datasets.MNIST(root='./data', train=True, transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = mnist_ds[0]\n",
    "v1, v2 = TwoTransform(mnist_aug)(img)\n",
    "\n",
    "def unnormalize(tensor):\n",
    "    return tensor * 0.3081 + 0.1307\n",
    "\n",
    "v1_img = unnormalize(v1).squeeze().numpy()\n",
    "v2_img = unnormalize(v2).squeeze().numpy()\n",
    "orig_img = transforms.ToTensor()(img).squeeze().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(9,3))\n",
    "axes[0].imshow(orig_img, cmap='gray')\n",
    "axes[0].set_title(\"Оригинальное\")\n",
    "axes[1].imshow(v1_img, cmap='gray')\n",
    "axes[1].set_title(\"Аугментировано 1\")\n",
    "axes[2].imshow(v2_img, cmap='gray')\n",
    "axes[2].set_title(\"Аугментировано 2\")\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Энкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, rep_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1, 1), # 28x28\n",
    "            nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 14x14\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 7x7\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten() # 1x1\n",
    "        )\n",
    "        self.fc = nn.Linear(128, rep_dim) # 1x1x128 -> 128\n",
    "    def forward(self, x): return self.fc(self.net(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проекционная и предикторные головы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYOL модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOL:\n",
    "    def __init__(self, encoder, projector_dim, pred_hidden, tau):\n",
    "        # Энкодер ученика\n",
    "        self.student_encoder = encoder\n",
    "        # Проекционная голова ученика\n",
    "        self.student_projector = MLP(encoder.fc.out_features, pred_hidden, projector_dim)\n",
    "        # Предикторная голова ученика (Без нее не сходится( )\n",
    "\n",
    "        # Энкодер и голова учителя (одинаковое состояние)\n",
    "        self.student_predictor = MLP(projector_dim, pred_hidden, projector_dim)\n",
    "        self.teacher_encoder = copy.deepcopy(encoder)\n",
    "        self.teacher_projector = copy.deepcopy(self.student_projector)\n",
    "        # Замороска параметров учителя (обновление только через EMA)\n",
    "        self._set_requires_grad(self.teacher_encoder, False)\n",
    "        self._set_requires_grad(self.teacher_projector, False)\n",
    "        self.teacher_encoder.eval()\n",
    "        self.teacher_projector.eval()\n",
    "        self.tau = tau\n",
    "    @staticmethod\n",
    "    def _set_requires_grad(model, req):\n",
    "        # Выключает градиенты для всех параметров модели\n",
    "        for p in model.parameters(): p.requires_grad = req\n",
    "    def to(self, device):\n",
    "        self.student_encoder.to(device)\n",
    "        self.student_projector.to(device)\n",
    "        self.student_predictor.to(device)\n",
    "        self.teacher_encoder.to(device)\n",
    "        self.teacher_projector.to(device)\n",
    "    def student_forward(self, x):\n",
    "        y = self.student_encoder(x)\n",
    "        z = self.student_projector(y)\n",
    "        p = self.student_predictor(z)\n",
    "        return y, z, p\n",
    "    @torch.no_grad()\n",
    "    def teacher_forward(self, x):\n",
    "        y = self.teacher_encoder(x)\n",
    "        z = self.teacher_projector(y)\n",
    "        return y, z\n",
    "    @torch.no_grad()\n",
    "    def update_teacher(self):\n",
    "        # Обновление для параметров\n",
    "        for param_q, param_k in zip(self.student_encoder.parameters(), self.teacher_encoder.parameters()):\n",
    "            param_k.mul_(self.tau).add_(param_q, alpha=1.0 - self.tau)\n",
    "        for param_q, param_k in zip(self.student_projector.parameters(), self.teacher_projector.parameters()):\n",
    "            param_k.mul_(self.tau).add_(param_q, alpha=1.0 - self.tau)\n",
    "\n",
    "        # Обновление для буферов BatchNorm\n",
    "        for m_s, m_t in zip(self.student_encoder.modules(), self.teacher_encoder.modules()):\n",
    "            if isinstance(m_s, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "                m_t.running_mean.mul_(self.tau).add_(m_s.running_mean, alpha=1.0 - self.tau)\n",
    "                m_t.running_var.mul_(self.tau).add_(m_s.running_var, alpha=1.0 - self.tau)\n",
    "\n",
    "        for m_s, m_t in zip(self.student_projector.modules(), self.teacher_projector.modules()):\n",
    "            if isinstance(m_s, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
    "                m_t.running_mean.mul_(self.tau).add_(m_s.running_mean, alpha=1.0 - self.tau)\n",
    "                m_t.running_var.mul_(self.tau).add_(m_s.running_var, alpha=1.0 - self.tau)\n",
    "\n",
    "def byol_loss(p, z_target):\n",
    "    # Приближение двух аугментаций (косинусное сходство)\n",
    "    p = F.normalize(p, dim=-1)\n",
    "    z = F.normalize(z_target, dim=-1)\n",
    "    return 2 - 2 * (p * z).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции для проверки коллапса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_collapse_loader(n_samples=512):\n",
    "    ds = datasets.MNIST(root='./data', train=True, transform=linear_aug, download=True)\n",
    "    subset_idx = torch.randperm(len(ds))[:n_samples]\n",
    "    subset = torch.utils.data.Subset(ds, subset_idx)\n",
    "    loader = DataLoader(subset, batch_size=256, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_trace_cov(encoder, loader, device):\n",
    "    encoder.eval()\n",
    "    feats = []\n",
    "\n",
    "    for x, _ in loader:\n",
    "        x = x.to(device)\n",
    "        y = encoder(x)\n",
    "        feats.append(y.cpu())\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "\n",
    "    # центрируем\n",
    "    mu = feats.mean(dim=0, keepdim=True)\n",
    "    X = feats - mu\n",
    "\n",
    "    # ковариация\n",
    "    cov = (X.T @ X) / (X.size(0) - 1)\n",
    "\n",
    "    return torch.trace(cov).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цикл обучения BYOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_byol(byol, dataloader, optimizer, device, epochs, tau):\n",
    "    byol.tau = tau\n",
    "    byol.to(device)\n",
    "\n",
    "    loss_list = []\n",
    "    trace_list = []\n",
    "\n",
    "    collapse_loader = make_collapse_loader()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        byol.student_encoder.train()\n",
    "        byol.student_projector.train()\n",
    "        byol.student_predictor.train()\n",
    "\n",
    "        byol.teacher_encoder.eval()\n",
    "        byol.teacher_projector.eval()\n",
    "\n",
    "        current_epoch = 0.0\n",
    "\n",
    "        for (x1, x2), _ in tqdm(dataloader, desc=f\"BYOL epoch {epoch}/{epochs}\"):\n",
    "            x1, x2 = x1.to(device), x2.to(device)\n",
    "            _, z1, p1 = byol.student_forward(x1)\n",
    "            _, z2, p2 = byol.student_forward(x2)\n",
    "            with torch.no_grad():\n",
    "                _, z1_t = byol.teacher_forward(x1)\n",
    "                _, z2_t = byol.teacher_forward(x2)\n",
    "            loss = (byol_loss(p1, z2_t).mean() + byol_loss(p2, z1_t).mean()) * 0.5\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            byol.update_teacher()\n",
    "            current_epoch += loss.item() * x1.size(0)\n",
    "        avg_loss = current_epoch / len(dataloader.dataset)\n",
    "        loss_list.append(avg_loss)\n",
    "\n",
    "        # Коллапс чек\n",
    "        trace_val = compute_trace_cov(byol.student_encoder, collapse_loader, device)\n",
    "        trace_list.append(trace_val)\n",
    "\n",
    "        print(f\"Epoch {epoch}: BYOL loss = {avg_loss:.4f}, trace(cov) = {trace_val:.2f}\")\n",
    "    return loss_list, trace_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цикл обучения линейной головы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear(encoder, train_loader, test_loader, device, epochs, lr):\n",
    "    encoder.eval()\n",
    "    # Заморозка всех параметров энкодера\n",
    "    for p in encoder.parameters(): p.requires_grad = False\n",
    "    feat_dim = encoder.fc.out_features\n",
    "    linear = nn.Linear(feat_dim, 10).to(device)\n",
    "    opt = torch.optim.Adam(linear.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    acc_list = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        linear.train(); current = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad(): feats = encoder(x)\n",
    "            logits = linear(feats)\n",
    "            loss = criterion(logits, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            current += loss.item() * x.size(0)\n",
    "        avg = current / len(train_loader.dataset)\n",
    "        acc = evaluate_encoder_linear(encoder, linear, test_loader, device)\n",
    "        acc_list.append(acc)\n",
    "        print(f\"Linear eval epoch {epoch}: loss={avg:.4f}, acc={acc:.2f}%\")\n",
    "    return linear, acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка точности линейной головы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_encoder_linear(encoder, linear, test_loader, device):\n",
    "    encoder.eval(); linear.eval()\n",
    "    correct = 0; total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            feats = encoder(x)\n",
    "            preds = linear(feats).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка MNIST и применение аугментаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTTwoView(datasets.MNIST):\n",
    "    def __init__(self, root, train, transform, download):\n",
    "        super().__init__(root=root, train=train, transform=None, download=download)\n",
    "        self.twotransform = transform\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super().__getitem__(index)\n",
    "        v1, v2 = self.twotransform(img)\n",
    "        return (v1, v2), target\n",
    "\n",
    "def make_dataloaders(batch_size_pretrain=256, batch_size_eval=256, seed=42):\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "\n",
    "    # Для обучения BYOL\n",
    "    pretrain_ds = MNISTTwoView(root='./data', train=True, transform=TwoTransform(mnist_aug), download=True)\n",
    "    pretrain_loader = DataLoader(pretrain_ds, batch_size=batch_size_pretrain, shuffle=True, num_workers=0, drop_last=True, generator=g)\n",
    "\n",
    "    # Для обучения и тестирования линейной головы\n",
    "    train_ds = datasets.MNIST(root='./data', train=True, transform=linear_aug, download=True)\n",
    "    test_ds = datasets.MNIST(root='./data', train=False, transform=linear_aug, download=True)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size_eval, shuffle=True, num_workers=0, generator=g) # Винда\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size_eval, shuffle=False, num_workers=0)\n",
    "\n",
    "    return pretrain_loader, train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_epochs = 25\n",
    "linear_epochs = 50\n",
    "tau = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_loader, train_loader, test_loader = make_dataloaders()\n",
    "encoder = Encoder(rep_dim=128)\n",
    "byol = BYOL(encoder, projector_dim=64, pred_hidden=128, tau=tau)\n",
    "student_params = list(byol.student_encoder.parameters()) + list(byol.student_projector.parameters()) + list(byol.student_predictor.parameters())\n",
    "optimizer = torch.optim.Adam(student_params, lr=1e-3, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение BYOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list, trace_list = train_byol(byol, pretrain_loader, optimizer, device, epochs=pretrain_epochs, tau=tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение линейной головы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_encoder = byol.student_encoder\n",
    "_, acc_list = train_linear(frozen_encoder, train_loader, test_loader, device, epochs=linear_epochs, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение на случайно инициализированном энкодере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_encoder = Encoder(rep_dim=128).to(device)\n",
    "\n",
    "# Заморазка параметров энкодера (т.к. они случайные и не будут меняться)\n",
    "for p in random_encoder.parameters(): \n",
    "    p.requires_grad = False\n",
    "\n",
    "linear_random, acc_random_list = train_linear(random_encoder, train_loader, test_loader, device, epochs=linear_epochs, lr=1e-3)\n",
    "\n",
    "print(f\"Точность на случайном энкодере: {acc_random_list[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Графики процесса обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1, len(loss_list)+1), loss_list, marker='o')\n",
    "plt.title(\"BYOL Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1, len(acc_list)+1), acc_random_list, marker='o', color='green')\n",
    "plt.title(\"Linear Random Encoder Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace Cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(trace_list, marker='o')\n",
    "plt.title(\"Коллапс-чек: trace(cov)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Trace\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE График"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_embeddings_tsne(encoder, dataloader, device, n_samples=2000):\n",
    "    encoder.eval()\n",
    "    feats_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            feats = encoder(x)\n",
    "            feats_list.append(feats.cpu())\n",
    "            labels_list.append(y.cpu())\n",
    "            if len(torch.cat(labels_list)) >= n_samples:\n",
    "                break\n",
    "\n",
    "    feats = torch.cat(feats_list)[:n_samples]\n",
    "    labels = torch.cat(labels_list)[:n_samples]\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)\n",
    "    emb_2d = tsne.fit_transform(feats.numpy())\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    scatter = plt.scatter(emb_2d[:, 0], emb_2d[:, 1], c=labels, cmap='tab10', s=10, alpha=0.8)\n",
    "    plt.legend(*scatter.legend_elements(), title=\"Цифры\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title(\"TSNE\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_embeddings_tsne(frozen_encoder, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Матрица ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(encoder, linear, test_loader, device):\n",
    "    encoder.eval()\n",
    "    linear.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            feats = encoder(x)\n",
    "            preds = linear(feats).argmax(dim=1)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(10)))\n",
    "    disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "    plt.title(\"Матрица ошибок - BYOL\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(frozen_encoder, _, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогон по нескольким сидам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def sweep_tau(tau_list, seeds=[42, 123, 456], pretrain_epochs=25, linear_epochs=50, save_path=\"tau_sweep_results.json\"):\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for tau in tau_list:\n",
    "        acc_per_seed = []\n",
    "        print(f\"\\n=== Tau = {tau} ===\")\n",
    "        for seed in seeds:\n",
    "            print(f\"\\nSeed {seed}...\")\n",
    "            # Установка сида\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "            # Даталоадеры\n",
    "            pretrain_loader, train_loader, test_loader = make_dataloaders()\n",
    "\n",
    "            # Модель и BYOL\n",
    "            encoder = Encoder(rep_dim=128)\n",
    "            byol = BYOL(encoder, projector_dim=64, pred_hidden=128, tau=tau)\n",
    "            student_params = list(byol.student_encoder.parameters()) + list(byol.student_projector.parameters()) + list(byol.student_predictor.parameters())\n",
    "            optimizer = torch.optim.Adam(student_params, lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "            # Предобучение BYOL\n",
    "            _ = train_byol(byol, pretrain_loader, optimizer, device, epochs=pretrain_epochs, tau=tau)\n",
    "\n",
    "            # Линейная оценка\n",
    "            frozen_encoder = byol.student_encoder\n",
    "            _, acc_list = train_linear(frozen_encoder, train_loader, test_loader, device, epochs=linear_epochs, lr=1e-3)\n",
    "            final_acc = acc_list[-1]  # Берем последнюю эпоху\n",
    "\n",
    "            acc_per_seed.append(final_acc)\n",
    "            print(f\"Сид {seed} завершен: точность линейной головы = {final_acc:.2f}%\")\n",
    "\n",
    "        # Сохраняем результаты по tau\n",
    "        mean_acc = float(np.mean(acc_per_seed))\n",
    "        std_acc = float(np.std(acc_per_seed))\n",
    "        results[str(tau)] = {\n",
    "            \"seed_accuracies\": acc_per_seed,\n",
    "            \"mean\": mean_acc,\n",
    "            \"std\": std_acc\n",
    "        }\n",
    "\n",
    "        print(f\"\\nTau={tau}: mean={mean_acc:.2f}%, std={std_acc:.2f}%\")\n",
    "\n",
    "    # Сохраняем в JSON\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_values = [0.98]\n",
    "results = sweep_tau(tau_values, save_path=\"results/tau_98.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_values = [0.995]\n",
    "results = sweep_tau(tau_values, save_path=\"results/tau_995.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_values = [0.999]\n",
    "results = sweep_tau(tau_values, save_path=\"results/tau_999.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение графика по результатам прогонов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути к файлам\n",
    "files = {\n",
    "    \"0.98\": \"tau_98.json\",\n",
    "    \"0.995\": \"tau_995.json\",\n",
    "    \"0.999\": \"tau_999.json\"\n",
    "}\n",
    "\n",
    "taus = []\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "# Загружаем данные\n",
    "for tau, path in files.items():\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        result = data[tau]\n",
    "        taus.append(float(tau))\n",
    "        means.append(result[\"mean\"])\n",
    "        stds.append(result[\"std\"])\n",
    "\n",
    "# Преобразуем в массивы\n",
    "taus = np.array(taus)\n",
    "means = np.array(means)\n",
    "stds = np.array(stds)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(taus, means, yerr=stds, fmt='o-', capsize=5)\n",
    "plt.title(\"Зависимость точности от τ\")\n",
    "plt.xlabel(\"τ\")\n",
    "plt.ylabel(\"Точность (%)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Абляции для аугментаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_soft = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28, scale=(0.95, 1.0)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "aug_medium = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28, scale=(0.5, 1.0)),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(0, translate=(0.25,0.25), scale=(0.65,1.25), shear=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "aug_hard = transforms.Compose([\n",
    "    transforms.RandomAffine(\n",
    "        degrees=40,\n",
    "        translate=(0.9, 0.9),    # сдвиг цифры за пределы изображения\n",
    "        scale=(0.4, 1.5),\n",
    "        shear=30\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_augmentations(tau=0.98, \n",
    "                           aug_list=[('soft', aug_soft), ('med', aug_medium), ('hard', aug_hard)], \n",
    "                           seeds=[42,43],\n",
    "                           pretrain_epochs=25,\n",
    "                           linear_epochs=50):\n",
    "    table = {}\n",
    "\n",
    "    for name, aug in aug_list:\n",
    "        accs = []\n",
    "        print(f\"\\n=== Аугментация: {name} ===\")\n",
    "        for s in seeds:\n",
    "            print(f\"Seed {s}...\")\n",
    "            # Установка сидов\n",
    "            random.seed(s)\n",
    "            np.random.seed(s)\n",
    "            torch.manual_seed(s)\n",
    "            torch.cuda.manual_seed_all(s)\n",
    "\n",
    "            # Даталоадеры с текущей аугментацией для BYOL\n",
    "            pretrain_ds = MNISTTwoView(root='./data', train=True, transform=TwoTransform(aug), download=True)\n",
    "            pretrain_loader = DataLoader(pretrain_ds, batch_size=256, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "            # Даталоадеры для линейной головы\n",
    "            train_ds = datasets.MNIST(root='./data', train=True, transform=linear_aug, download=True)\n",
    "            test_ds = datasets.MNIST(root='./data', train=False, transform=linear_aug, download=True)\n",
    "            train_loader = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=0)\n",
    "            test_loader = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=0)\n",
    "\n",
    "            # Модель и BYOL\n",
    "            encoder = Encoder(rep_dim=128)\n",
    "            byol = BYOL(encoder, projector_dim=64, pred_hidden=128, tau=tau)\n",
    "            student_params = list(byol.student_encoder.parameters()) + list(byol.student_projector.parameters()) + list(byol.student_predictor.parameters())\n",
    "            optimizer = torch.optim.Adam(student_params, lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "            # Предобучение BYOL\n",
    "            _ = train_byol(byol, pretrain_loader, optimizer, device, epochs=pretrain_epochs, tau=tau)\n",
    "\n",
    "            # Линейная оценка\n",
    "            frozen_encoder = byol.student_encoder\n",
    "            _, acc_list = train_linear(frozen_encoder, train_loader, test_loader, device, epochs=linear_epochs, lr=1e-3)\n",
    "            final_acc = acc_list[-1]\n",
    "            accs.append(final_acc)\n",
    "            print(f\"Seed {s} завершен: точность линейной головы = {final_acc:.2f}%\")\n",
    "\n",
    "        table[name] = {'acc_mean': np.mean(accs), 'acc_std': np.std(accs, ddof=1)}\n",
    "\n",
    "    # Визуализация\n",
    "    labels = list(table.keys())\n",
    "    means = [table[k]['acc_mean'] for k in labels]\n",
    "    stds = [table[k]['acc_std'] for k in labels]\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar(labels, means, yerr=stds, capsize=5, color=['skyblue','orange','green'])\n",
    "    plt.ylabel(\"Точность (%)\")\n",
    "    plt.title(f\"Абляции: Сила аугментации (tau={tau})\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.show()\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ablation = ablation_augmentations(tau=0.98)\n",
    "print(results_ablation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты {'soft': {'acc_mean': np.float64(96.4), 'acc_std': np.float64(0.6929646455628193)}, 'med': {'acc_mean': np.float64(98.20), 'acc_std': np.float64(0.1979898987322341)}, 'hard': {'acc_mean': np.float64(79.87), 'acc_std': np.float64(5.289158723275378)}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
